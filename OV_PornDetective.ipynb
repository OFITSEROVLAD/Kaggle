{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pymorphy2 + tokenize_normalize + Pipeline(CountVectorizer, TfidfTransformer, SGDClassifier) + grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE='+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m.kp.md</td>\n",
       "      <td>экс-министр экономики молдовы - главе мидэи, ц...</td>\n",
       "      <td>False</td>\n",
       "      <td>m.kp.md экс-министр экономики молдовы - главе ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>www.kp.by</td>\n",
       "      <td>эта песня стала известна многим телезрителям б...</td>\n",
       "      <td>False</td>\n",
       "      <td>www.kp.by эта песня стала известна многим теле...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fanserials.tv</td>\n",
       "      <td>банши 4 сезон 2 серия бремя красоты смотреть о...</td>\n",
       "      <td>False</td>\n",
       "      <td>fanserials.tv банши 4 сезон 2 серия бремя крас...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>colorbox.spb.ru</td>\n",
       "      <td>не беси меня картинки</td>\n",
       "      <td>False</td>\n",
       "      <td>colorbox.spb.ru не беси меня картинки</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tula-sport.ru</td>\n",
       "      <td>в новомосковске сыграют следж-хоккеисты алекси...</td>\n",
       "      <td>False</td>\n",
       "      <td>tula-sport.ru в новомосковске сыграют следж-хо...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              url                                              title  \\\n",
       "0   0          m.kp.md  экс-министр экономики молдовы - главе мидэи, ц...   \n",
       "1   1        www.kp.by  эта песня стала известна многим телезрителям б...   \n",
       "2   2    fanserials.tv  банши 4 сезон 2 серия бремя красоты смотреть о...   \n",
       "3   3  colorbox.spb.ru                              не беси меня картинки   \n",
       "4   4    tula-sport.ru  в новомосковске сыграют следж-хоккеисты алекси...   \n",
       "\n",
       "   target                                                  n  \n",
       "0   False  m.kp.md экс-министр экономики молдовы - главе ...  \n",
       "1   False  www.kp.by эта песня стала известна многим теле...  \n",
       "2   False  fanserials.tv банши 4 сезон 2 серия бремя крас...  \n",
       "3   False              colorbox.spb.ru не беси меня картинки  \n",
       "4   False  tula-sport.ru в новомосковске сыграют следж-хо...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df['title'] = train_df['title'].str.lower()\n",
    "train_df['url'] = train_df['url'].str.lower()\n",
    "train_df['url'].fillna(train_df['title'], inplace=True)\n",
    "train_df['n'] = train_df['url'] + ' ' +  train_df['title']\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135309</td>\n",
       "      <td>www.kommersant.ru</td>\n",
       "      <td>шестой кассационный суд в самаре начнет работу...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135310</td>\n",
       "      <td>urexpert.online</td>\n",
       "      <td>что такое индексация алиментов, кем и в каких ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135311</td>\n",
       "      <td>imperimeha.ru</td>\n",
       "      <td>женщинам | империя меха - part 12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135312</td>\n",
       "      <td>national-porn.com</td>\n",
       "      <td>небритые, волосатые киски: порно всех стран и ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135313</td>\n",
       "      <td>2gis.ru</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                url  \\\n",
       "0  135309  www.kommersant.ru   \n",
       "1  135310    urexpert.online   \n",
       "2  135311      imperimeha.ru   \n",
       "3  135312  national-porn.com   \n",
       "4  135313            2gis.ru   \n",
       "\n",
       "                                               title  \n",
       "0  шестой кассационный суд в самаре начнет работу...  \n",
       "1  что такое индексация алиментов, кем и в каких ...  \n",
       "2                  женщинам | империя меха - part 12  \n",
       "3  небритые, волосатые киски: порно всех стран и ...  \n",
       "4                                                 67  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df['title'] = test_df['title'].str.lower()\n",
    "test_df['url'] = test_df['url'].str.lower()\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import re\n",
    "\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "retoken = re.compile(r'[\\'\\w\\-]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_normalize(text):\n",
    "    text = retoken.findall(text.lower())\n",
    "    text = [morph.parse(x)[0].normal_form for x in text]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m.kp.md</td>\n",
       "      <td>экс-министр экономики молдовы - главе мидэи, ц...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>www.kp.by</td>\n",
       "      <td>эта песня стала известна многим телезрителям б...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fanserials.tv</td>\n",
       "      <td>банши 4 сезон 2 серия бремя красоты смотреть о...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>colorbox.spb.ru</td>\n",
       "      <td>не беси меня картинки</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tula-sport.ru</td>\n",
       "      <td>в новомосковске сыграют следж-хоккеисты алекси...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              url                                              title  \\\n",
       "0   0          m.kp.md  экс-министр экономики молдовы - главе мидэи, ц...   \n",
       "1   1        www.kp.by  эта песня стала известна многим телезрителям б...   \n",
       "2   2    fanserials.tv  банши 4 сезон 2 серия бремя красоты смотреть о...   \n",
       "3   3  colorbox.spb.ru                              не беси меня картинки   \n",
       "4   4    tula-sport.ru  в новомосковске сыграют следж-хоккеисты алекси...   \n",
       "\n",
       "   target  \n",
       "0   False  \n",
       "1   False  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['title'] = train_df['title'].astype(str)\n",
    "train_df['url'] = train_df['url'].astype(str)\n",
    "train_df['n'] = train_df['n'].astype(str)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 46s, sys: 613 ms, total: 4min 47s\n",
      "Wall time: 4min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['n_norm'] = train_df['n'].apply(tokenize_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.54 s, sys: 35.5 ms, total: 8.58 s\n",
      "Wall time: 8.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df['url_norm'] = train_df['url'].apply(tokenize_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 44s, sys: 390 ms, total: 5min 44s\n",
      "Wall time: 5min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df['title_norm'] = test_df['title'].apply(tokenize_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.5 s, sys: 12.1 ms, total: 11.5 s\n",
      "Wall time: 11.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test_df['url_norm'] = test_df['url'].apply(tokenize_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>target</th>\n",
       "      <th>title_norm</th>\n",
       "      <th>url_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m.kp.md</td>\n",
       "      <td>экс-министр экономики молдовы - главе мидэи, ц...</td>\n",
       "      <td>False</td>\n",
       "      <td>экс-министр экономика молдова - глава мидэя це...</td>\n",
       "      <td>m kp md</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>www.kp.by</td>\n",
       "      <td>эта песня стала известна многим телезрителям б...</td>\n",
       "      <td>False</td>\n",
       "      <td>этот песня стать известный многий телезритель ...</td>\n",
       "      <td>www kp by</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>fanserials.tv</td>\n",
       "      <td>банши 4 сезон 2 серия бремя красоты смотреть о...</td>\n",
       "      <td>False</td>\n",
       "      <td>банша 4 сезон 2 серия бремя красота смотреть о...</td>\n",
       "      <td>fanserials tv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>colorbox.spb.ru</td>\n",
       "      <td>не беси меня картинки</td>\n",
       "      <td>False</td>\n",
       "      <td>не бесить я картинка</td>\n",
       "      <td>colorbox spb ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>tula-sport.ru</td>\n",
       "      <td>в новомосковске сыграют следж-хоккеисты алекси...</td>\n",
       "      <td>False</td>\n",
       "      <td>в новомосковск сыграть следж-хоккеист алексинс...</td>\n",
       "      <td>tula-sport ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id              url                                              title  \\\n",
       "0   0          m.kp.md  экс-министр экономики молдовы - главе мидэи, ц...   \n",
       "1   1        www.kp.by  эта песня стала известна многим телезрителям б...   \n",
       "2   2    fanserials.tv  банши 4 сезон 2 серия бремя красоты смотреть о...   \n",
       "3   3  colorbox.spb.ru                              не беси меня картинки   \n",
       "4   4    tula-sport.ru  в новомосковске сыграют следж-хоккеисты алекси...   \n",
       "\n",
       "   target                                         title_norm         url_norm  \n",
       "0   False  экс-министр экономика молдова - глава мидэя це...          m kp md  \n",
       "1   False  этот песня стать известный многий телезритель ...        www kp by  \n",
       "2   False  банша 4 сезон 2 серия бремя красота смотреть о...    fanserials tv  \n",
       "3   False                               не бесить я картинка  colorbox spb ru  \n",
       "4   False  в новомосковск сыграть следж-хоккеист алексинс...    tula-sport ru  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>title_norm</th>\n",
       "      <th>url_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135309</td>\n",
       "      <td>www.kommersant.ru</td>\n",
       "      <td>шестой кассационный суд в самаре начнет работу...</td>\n",
       "      <td>шесть кассационный суд в самар начать работа в...</td>\n",
       "      <td>www kommersant ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>135310</td>\n",
       "      <td>urexpert.online</td>\n",
       "      <td>что такое индексация алиментов, кем и в каких ...</td>\n",
       "      <td>что такой индексация алименты кто и в какой сл...</td>\n",
       "      <td>urexpert online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>135311</td>\n",
       "      <td>imperimeha.ru</td>\n",
       "      <td>женщинам | империя меха - part 12</td>\n",
       "      <td>женщина империя мех - part 12</td>\n",
       "      <td>imperimeha ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>135312</td>\n",
       "      <td>national-porn.com</td>\n",
       "      <td>небритые, волосатые киски: порно всех стран и ...</td>\n",
       "      <td>небритый волосатый киска порно весь страна и н...</td>\n",
       "      <td>national-porn com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135313</td>\n",
       "      <td>2gis.ru</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>2gis ru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                url  \\\n",
       "0  135309  www.kommersant.ru   \n",
       "1  135310    urexpert.online   \n",
       "2  135311      imperimeha.ru   \n",
       "3  135312  national-porn.com   \n",
       "4  135313            2gis.ru   \n",
       "\n",
       "                                               title  \\\n",
       "0  шестой кассационный суд в самаре начнет работу...   \n",
       "1  что такое индексация алиментов, кем и в каких ...   \n",
       "2                  женщинам | империя меха - part 12   \n",
       "3  небритые, волосатые киски: порно всех стран и ...   \n",
       "4                                                 67   \n",
       "\n",
       "                                          title_norm           url_norm  \n",
       "0  шесть кассационный суд в самар начать работа в...  www kommersant ru  \n",
       "1  что такой индексация алименты кто и в какой сл...    urexpert online  \n",
       "2                      женщина империя мех - part 12      imperimeha ru  \n",
       "3  небритый волосатый киска порно весь страна и н...  national-porn com  \n",
       "4                                                 67            2gis ru  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MODE == '+':\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_df[[\"n\"]], train_df[\"target\"].astype(int).values, test_size=0.2, random_state=42)\n",
    "else:\n",
    "    X_train = train_df[[\"url_norm\", \"title_norm\"]]\n",
    "    y_train = train_df[\"target\"].astype(int).values\n",
    "    X_test = test_df[[\"url_norm\", \"title_norm\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108247, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', SGDClassifier( penalty= None),)\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = X_train[\"n\"].values\n",
    "\n",
    "b = X_test[\"n\"].values\n",
    "\n",
    "aaaaaa = text_clf.fit(a, y_train)\n",
    "predicted = aaaaaa.predict(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9645347074871173\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-b7ca46fcdcfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "print(f1_score(predicted, y_test))\n",
    "print(metrics.classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = X_train[\"url_norm\"].values\n",
    "bb = X_test[\"url_norm\"].values\n",
    "\n",
    "\n",
    "predicted_url = text_clf.fit(aa, y_train).predict(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8747130206625122\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     24304\n",
      "           1       0.80      0.97      0.87      2758\n",
      "\n",
      "    accuracy                           0.97     27062\n",
      "   macro avg       0.90      0.97      0.93     27062\n",
      "weighted avg       0.98      0.97      0.97     27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(predicted_url, y_test))\n",
    "print(metrics.classification_report(predicted_url, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110\n",
      "1475\n"
     ]
    }
   ],
   "source": [
    "y_pred = [int(\"webcam\" in url or \"porno\" in url or \"xxx\" in url or 'sex' in url ) for url in bb]\n",
    "y_pred1 = [int(\"мастурбировать\" in text or \"пенис\" in text or \"проститутка\" in text or \"елдак\" in text or \"ебёт\" in text or \"член в\" in text or \"выебал\" in text or \"xxx\" in text and not \"xxxtentac\" in text or \"porn\" in text or \"sex\" in text) for text in b]\n",
    "print(sum(y_pred))\n",
    "print(sum(y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49617977528089885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95     25952\n",
      "           1       0.33      0.99      0.50      1110\n",
      "\n",
      "    accuracy                           0.92     27062\n",
      "   macro avg       0.67      0.95      0.73     27062\n",
      "weighted avg       0.97      0.92      0.94     27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_pred, y_test))\n",
    "print(metrics.classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6076843198338526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     25587\n",
      "           1       0.44      0.99      0.61      1475\n",
      "\n",
      "    accuracy                           0.93     27062\n",
      "   macro avg       0.72      0.96      0.78     27062\n",
      "weighted avg       0.97      0.93      0.94     27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(y_pred1, y_test)) \n",
    "print(metrics.classification_report(y_pred1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9640140433001754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     23566\n",
      "           1       0.99      0.94      0.96      3496\n",
      "\n",
      "    accuracy                           0.99     27062\n",
      "   macro avg       0.99      0.97      0.98     27062\n",
      "weighted avg       0.99      0.99      0.99     27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(predicted_url | predicted | y_pred | y_pred1, y_test))\n",
    "print(metrics.classification_report(predicted_url | predicted | y_pred | y_pred1, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9598315029336543\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     23755\n",
      "           1       0.96      0.96      0.96      3307\n",
      "\n",
      "    accuracy                           0.99     27062\n",
      "   macro avg       0.98      0.98      0.98     27062\n",
      "weighted avg       0.99      0.99      0.99     27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(predicted | ((np.array(predicted_url)+np.array(y_pred))//2) | ((np.array(y_pred)+np.array(y_pred1))//2) | ((np.array(predicted_url)+np.array(y_pred1))//2), y_test))\n",
    "print(metrics.classification_report(predicted | ((np.array(predicted_url)+np.array(y_pred))//2) | ((np.array(y_pred)+np.array(y_pred1))//2) | ((np.array(predicted_url)+np.array(y_pred1))//2), y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T14:22:17.785707Z",
     "start_time": "2020-04-07T14:22:17.781254Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 181\n",
    "\n",
    "X_test[(predicted_url | predicted | y_pred | y_pred1 != y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     23566\n",
      "           1       0.99      0.94      0.96      3496\n",
      "\n",
      "    accuracy                           0.99     27062\n",
      "   macro avg       0.99      0.97      0.98     27062\n",
      "weighted avg       0.99      0.99      0.99     27062\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(predicted_url | predicted | y_pred | y_pred1, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"target\"] = (predicted_url | predicted | y_pred | y_pred1).astype(bool)\n",
    "\n",
    "test_df[[\"id\", \"target\"]].to_csv(\"Normalize_SGDC_penalty_None.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = pd.read_csv(\"Normalize_SGDC_penalty_None.csv\")\n",
    "answer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for penalty_p in [ 'l2', 'l1', 'elasticnet', 'None']:\n",
    "    for loss_p in ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron']:\n",
    "                text_clf = Pipeline([('vect', CountVectorizer(ngram_range=(1, 3))),\n",
    "                                 ('tfidf', TfidfTransformer()),\n",
    "                                 ('MNB',  SGDClassifier( n_jobs=-1, penalty=penalty_p, loss = loss_p) ),\n",
    "                ])\n",
    "                a = X_train[\"title_norm\"].values\n",
    "                b = X_test[\"title_norm\"].values\n",
    "                aaaaaa = text_clf.fit(a, y_train)\n",
    "                predicted = aaaaaa.predict(b)\n",
    "                print('penalty =',penalty_p,' loss =' ,loss_p, ' - ', f1_score(predicted, y_test))\n",
    "                print(metrics.classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_MNB = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('MNB',  MultinomialNB(alpha = 0.115),) #0.9532083523853071\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('MNB',\n",
       "                 MultinomialNB(alpha=0.115, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_MNB = X_train[\"title_norm\"].values\n",
    "\n",
    "b_MNB = X_test[\"title_norm\"].values\n",
    "\n",
    "aaaaaa_MNB = text_MNB.fit(a_MNB, y_train)\n",
    "predicted_MNB = aaaaaa_MNB.predict(b_MNB)\n",
    "aaaaaa_MNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9202417809228953\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(predicted_MNB, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение на двух колонках\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_column(X):\n",
    "    return X.iloc[:, 0]\n",
    "\n",
    "def second_column(X):\n",
    "    return X.iloc[:, 1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline to get all tfidf and word count for first column\n",
    "pipeline_one = Pipeline([\n",
    "    ('column_selection', FunctionTransformer(first_column, validate=False)),\n",
    "    ('feature-extractors', FeatureUnion([('tfidf', TfidfVectorizer()),\n",
    "                                        ('counts', CountVectorizer())\n",
    "\n",
    "    ]))\n",
    "])\n",
    "\n",
    "# Then a second pipeline to do the same for the second column\n",
    "pipeline_two = Pipeline([\n",
    "    ('column_selection', FunctionTransformer(second_column, validate=False)),\n",
    "    ('feature-extractors', FeatureUnion([('tfidf', TfidfVectorizer()),\n",
    "                                        ('counts', CountVectorizer())\n",
    "\n",
    "    ]))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T14:21:54.182872Z",
     "start_time": "2020-04-07T14:21:54.178332Z"
    }
   },
   "outputs": [],
   "source": [
    "# Then you would again feature union these pipelines \n",
    "# to get different feature selection for each column\n",
    "final_transformer = FeatureUnion([('first-column-features', pipeline_one),\n",
    "                                  ('second-column-feature', pipeline_two),\n",
    "                                  ('clf', SGDClassifier()),\n",
    "                                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<108247x309430 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2451606 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_transformer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-07T14:22:30.424057Z",
     "start_time": "2020-04-07T14:22:30.419230Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicted_S = final_transformer.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
